spring:
  application:
    name: mercenary-ai
  profiles:
    active: ${APP_PROFILE:dev}
  # Disable static resource caching for development
  web:
    resources:
      cache:
        cachecontrol:
          no-cache: true
          no-store: true

  # =================================================================
  # CRITICAL SECURITY WARNING
  # =================================================================
  # DO NOT COMMIT REAL CREDENTIALS TO THIS FILE.
  # THIS FILE IS PUBLICLY VISIBLE IN GIT HISTORY.
  #
  # USE ENVIRONMENT VARIABLES FOR ALL SECRETS.
  # 
  # MONGODB_URI should be set in your run configuration or OS environment.
  # Example: MONGODB_URI=mongodb+srv://user:pass@cluster.mongodb.net/mercenary
  # =================================================================

  # --- THE BAN HAMMER ---
  # This tells Spring: "Do NOT load your default MongoDB Vector Store logic. I have my own."
  autoconfigure:
    exclude:
      - org.springframework.ai.autoconfigure.vectorstore.mongo.MongoDBAtlasVectorStoreAutoConfiguration
      - org.springframework.ai.autoconfigure.openai.OpenAiAutoConfiguration
      - org.springframework.ai.autoconfigure.azure.openai.AzureOpenAiAutoConfiguration
      - org.springframework.ai.autoconfigure.vertexai.gemini.VertexAiGeminiAutoConfiguration
      - org.springframework.ai.autoconfigure.vertexai.palm2.VertexAiPalm2AutoConfiguration
      - org.springframework.ai.autoconfigure.anthropic.AnthropicAutoConfiguration

  data:
    mongodb:
      # SECURE DEFAULT: Localhost (No Auth) - Safe for dev
      # PRODUCTION: WE WILL READ 'MONGODB_URI' FROM ENVIRONMENT
      uri: ${MONGODB_URI:mongodb://localhost:27017/mercenary}
  servlet:
    multipart:
      max-file-size: 50MB
      max-request-size: 50MB
  ai:
    ollama:
      base-url: ${OLLAMA_URL:http://localhost:11434}
      chat:
        options:
          model: ${LLM_MODEL:llama3.1:8b}
          # Lower temperature for more focused, grounded responses (reduces hallucinations)
          temperature: ${LLM_TEMPERATURE:0.0}
          # Cap output tokens aggressively to prevent runaway generation
          num-predict: ${LLM_NUM_PREDICT:256}
          # Context window size (reduce for speed if needed)
          num-ctx: ${LLM_NUM_CTX:4096}
          # Stop sequences to prevent rambling past the answer
          stop:
            - "\n\nSources:"
            - "\n\n---"
            - "\n\nNote:"
            - "\n\nAdditional"
      embedding:
        model: ${EMBEDDING_MODEL:nomic-embed-text}
    vectorstore:
      mongodb:
        atlas:
          collection-name: vector_store
          initialize-schema: true
          path-name: embedding
          index-name: vector_index

# ============================================
# Server/Cookie Security
# ============================================
server:
  # M-14: Tomcat request body and connection limits to prevent resource exhaustion
  tomcat:
    max-http-form-post-size: 52428800  # 50MB â€” match multipart limit
    connection-timeout: 20000          # 20 seconds
    max-connections: 200
    threads:
      max: 200
      min-spare: 10
    accept-count: 100
  servlet:
    session:
      cookie:
        same-site: Lax
        http-only: true
        secure: ${COOKIE_SECURE:true}  # Set true for HTTPS deployments

# ============================================
# Logging (include correlation ID in default pattern)
# ============================================
logging:
  pattern:
    level: "%5p [%X{correlationId:-}]"

# ============================================
# Custom App Config
# ============================================
app:
  db-init: true
  # Authentication mode: DEV, OIDC, or CAC
  auth-mode: ${AUTH_MODE:STANDARD}
  security:
    # Comma-separated list of trusted proxy IPs for X-Forwarded-For
    trusted-proxies: ${TRUSTED_PROXIES:}
  guardrails:
    enabled: ${GUARDRAILS_ENABLED:true}
    llm-enabled: ${GUARDRAILS_LLM_ENABLED:true}
    llm-timeout-ms: ${GUARDRAILS_LLM_TIMEOUT_MS:3000}
    strict-mode: ${GUARDRAILS_STRICT_MODE:false}
    llm-circuit-breaker:
      enabled: ${GUARDRAILS_LLM_CB_ENABLED:true}
      failure-threshold: ${GUARDRAILS_LLM_CB_FAILURE_THRESHOLD:3}
      open-seconds: ${GUARDRAILS_LLM_CB_OPEN_SECONDS:30}
      half-open-max-calls: ${GUARDRAILS_LLM_CB_HALF_OPEN_CALLS:1}
  audit:
    # Fail-closed is enforced in govcloud profile at runtime
    fail-closed: ${AUDIT_FAIL_CLOSED:false}
  auth:
    lockout:
      enabled: ${AUTH_LOCKOUT_ENABLED:true}
      max-attempts: ${AUTH_LOCKOUT_MAX_ATTEMPTS:5}
      window-minutes: ${AUTH_LOCKOUT_WINDOW_MINUTES:15}
      duration-minutes: ${AUTH_LOCKOUT_DURATION_MINUTES:15}
  tokenization:
    enabled: ${TOKENIZATION_ENABLED:true}
    store-originals: ${TOKENIZATION_STORE_ORIGINALS:true}
    secret-key: ${TOKENIZATION_SECRET_KEY:}
    hmac-key: ${TOKENIZATION_HMAC_KEY:}
    aes-key: ${TOKENIZATION_AES_KEY:}
    active-key-id: ${TOKENIZATION_ACTIVE_KEY_ID:}
    hmac-keys: ${TOKENIZATION_HMAC_KEYS:}
    aes-keys: ${TOKENIZATION_AES_KEYS:}
    hmac-keys-kms: ${TOKENIZATION_HMAC_KEYS_KMS:}
    aes-keys-kms: ${TOKENIZATION_AES_KEYS_KMS:}

# ============================================
# SENTINEL Configuration
# Single-product with 3 sectors: GOVERNMENT, MEDICAL, ENTERPRISE
# ============================================
sentinel:
  # LLM timeout for complex queries
  # Default 180s - increased from 120s to handle DOCUMENT routing with local Ollama
  # For faster hardware or cloud LLM, you can reduce this
  llm:
    timeout-seconds: ${LLM_TIMEOUT_SECONDS:180}
  # Performance tuning knobs
  performance:
    rag-core-threads: ${RAG_CORE_THREADS:8}
    rag-max-threads: ${RAG_MAX_THREADS:16}
    rag-queue-capacity: ${RAG_QUEUE_CAPACITY:400}
    reranker-threads: ${RERANKER_THREADS:4}
    rag-future-timeout-seconds: ${RAG_FUTURE_TIMEOUT_SECONDS:8}
  # RAG prompt/context limits
  rag:
    max-context-chars: ${RAG_MAX_CONTEXT_CHARS:12000}
    max-doc-chars: ${RAG_MAX_DOC_CHARS:2000}
    max-visual-chars: ${RAG_MAX_VISUAL_CHARS:1200}
    max-overview-chars: ${RAG_MAX_OVERVIEW_CHARS:2400}
    max-docs: ${RAG_MAX_DOCS:12}
    max-visual-docs: ${RAG_MAX_VISUAL_DOCS:6}
    temporal-filtering:
      # Apply documentYear prefilters when the user query expresses a year constraint (e.g. "between 2020 and 2022").
      enabled: ${RAG_TEMPORAL_FILTERING_ENABLED:false}

  # Domain thesaurus: configurable acronym/synonym expansion (Phase 3)
  thesaurus:
    enabled: ${THESAURUS_ENABLED:true}
    # Opt-in: unit conversions (e.g., PSI <-> MPa, F <-> C). Keep off unless you validate with benchmark.
    unit-conversion-enabled: ${THESAURUS_UNIT_CONVERSION_ENABLED:false}
    # Opt-in: index thesaurus entries into the vector store as type=thesaurus documents.
    vector-index-enabled: ${THESAURUS_VECTOR_INDEX_ENABLED:false}
    vector-index:
      cache-ttl-seconds: ${THESAURUS_VECTOR_INDEX_CACHE_TTL_SECONDS:21600}
    max-query-variants: ${THESAURUS_MAX_QUERY_VARIANTS:4}
    # Configure per-department entries here or via environment-specific overlays.
    # Example:
    # entries:
    #   GLOBAL:
    #     HIPAA:
    #       - Health Insurance Portability and Accountability Act
    entries: {}

  ingest:
    chunking:
      chunk-size-tokens: ${INGEST_CHUNK_SIZE_TOKENS:800}
      min-chunk-size-chars: ${INGEST_MIN_CHUNK_SIZE_CHARS:350}
      min-chunk-length-to-embed: ${INGEST_MIN_CHUNK_LENGTH_TO_EMBED:5}
      max-num-chunks: ${INGEST_MAX_NUM_CHUNKS:10000}
      keep-separator: ${INGEST_KEEP_SEPARATOR:true}
    chunk-merge:
      enabled: ${INGEST_CHUNK_MERGE_ENABLED:true}
      min-tokens: ${INGEST_CHUNK_MERGE_MIN_TOKENS:512}
      max-tokens: ${INGEST_CHUNK_MERGE_MAX_TOKENS:2000}
    tables:
      enabled: ${INGEST_TABLES_ENABLED:true}
      max-tables-per-document: ${INGEST_MAX_TABLES_PER_DOCUMENT:50}
      max-table-chars: ${INGEST_MAX_TABLE_CHARS:20000}
    resilience:
      enabled: ${INGEST_RESILIENCE_ENABLED:true}
      max-retries: ${INGEST_MAX_RETRIES:1}
      failure-threshold-percent: ${INGEST_FAILURE_THRESHOLD_PERCENT:50}
      failure-threshold-min-samples: ${INGEST_FAILURE_THRESHOLD_MIN_SAMPLES:5}
      checkpoint-path: ${INGEST_CHECKPOINT_PATH:${java.io.tmpdir}/sentinel-ingestion/session.json}
      failed-docs-max: ${INGEST_FAILED_DOCS_MAX:500}

  source-retention:
    pdf:
      # Retain source PDF bytes in-memory for on-demand page/region rendering ("View Source").
      enabled: ${SOURCE_RETENTION_PDF_ENABLED:true}
      # Conservative default for HIPAA strict: do not retain source bytes unless explicitly enabled.
      allow-hipaa-strict: ${SOURCE_RETENTION_ALLOW_HIPAA_STRICT:false}
      max-bytes: ${SOURCE_RETENTION_PDF_MAX_BYTES:52428800}
      cache:
        ttl-hours: ${SOURCE_RETENTION_PDF_CACHE_TTL_HOURS:1}
        max-total-bytes: ${SOURCE_RETENTION_PDF_CACHE_MAX_TOTAL_BYTES:268435456}

  source-render:
    dpi: ${SOURCE_RENDER_DPI:160}
    max-output-pixels: ${SOURCE_RENDER_MAX_OUTPUT_PIXELS:3686400}

  # License validation
  # When no key and no signing secret are set, runs in unlicensed mode (backward compatible).
  # To enforce licensing, set both LICENSE_KEY and LICENSE_SIGNING_SECRET.
  license:
    key: ${LICENSE_KEY:}
    signing-secret: ${LICENSE_SIGNING_SECRET:}

  # Vector store selection (local vs Atlas)
  vectorstore:
    force-local: ${SENTINEL_FORCE_LOCAL_VECTOR_STORE:false}
    force-atlas: ${SENTINEL_FORCE_ATLAS_VECTOR_STORE:false}
  embedding:
    # Embed in batches for better ingestion throughput (Phase 5.2 evaluation).
    batch-size: ${EMBEDDING_BATCH_SIZE:128}
    # Optional target dimension guardrail. Set 0 to disable strict dimension targeting.
    target-dimensions: ${EMBEDDING_TARGET_DIMENSIONS:0}
    # Enables Document(media+text) embedding attempts for visual assets (falls back to text if unsupported).
    multimodal-enabled: ${EMBEDDING_MULTIMODAL_ENABLED:false}

# ============================================
# SENTINEL Advanced RAG Configuration
# Based on cutting-edge research papers
# ============================================
  # RAGPart Defense (arXiv:2512.24268v1)
  # Corpus poisoning defense via document partitioning
  ragpart:
    enabled: ${RAGPART_ENABLED:true}
    partitions: ${RAGPART_PARTITIONS:4}
    combination-size: ${RAGPART_COMBINATION_SIZE:3}
    suspicion-threshold: ${RAGPART_SUSPICION_THRESHOLD:0.4}

  # HGMem - HyperGraph Memory (arXiv:2512.23959v2)
  # Entity extraction and knowledge graph for document analysis
  #
  # indexing-enabled: Extract entities during document upload (enables Entity Network UI)
  # query-enabled: Multi-hop graph traversal at query time (slow - 5+ min for large corpora)
  #
  # Recommended: indexing=true, query=false (fast entity viz, no query slowdown)
  # For deep analysis: Enable query per-request via UI toggle
  hgmem:
    indexing-enabled: ${HGMEM_INDEXING:true}
    query-enabled: ${HGMEM_QUERY:false}
    max-memory-points: ${HGMEM_MAX_POINTS:50}
    merge-similarity-threshold: ${HGMEM_MERGE_THRESHOLD:0.7}

  # Sample Data Loader (dev mode only)
  # Auto-loads test documents into HyperGraphMemory for Entity Network visualization
  # Enable: SAMPLE_DATA_LOAD=true (requires dev profile)
  sample-data:
    load: ${SAMPLE_DATA_LOAD:false}
    path: classpath:test_docs/*.txt

  demo:
    enabled: ${SENTINEL_DEMO_ENABLED:true}
    path: ${SENTINEL_DEMO_PATH:classpath:demo_docs/*.*}
    max-files: ${SENTINEL_DEMO_MAX_FILES:50}

  casework:
    enabled: ${SENTINEL_CASEWORK_ENABLED:true}
    allow-regulated: ${SENTINEL_CASEWORK_ALLOW_REGULATED:false}

  workspace:
    enabled: ${SENTINEL_WORKSPACE_ENABLED:true}
    allow-regulated: ${SENTINEL_WORKSPACE_ALLOW_REGULATED:false}
    default-id: ${SENTINEL_WORKSPACE_DEFAULT_ID:workspace_default}

  reporting:
    schedules:
      enabled: ${SENTINEL_REPORTING_SCHEDULES_ENABLED:false}
      allow-regulated: ${SENTINEL_REPORTING_SCHEDULES_ALLOW_REGULATED:false}
      interval-ms: ${SENTINEL_REPORTING_SCHEDULES_INTERVAL_MS:300000}

  connectors:
    enabled: ${SENTINEL_CONNECTORS_ENABLED:true}
    allow-regulated: ${SENTINEL_CONNECTORS_ALLOW_REGULATED:false}
    sync-enabled: ${SENTINEL_CONNECTORS_SYNC_ENABLED:false}
    sync-cron: ${SENTINEL_CONNECTORS_SYNC_CRON:0 0 2 * * ?}
    sharepoint:
      enabled: ${SENTINEL_SHAREPOINT_ENABLED:false}
      graph-base: ${SENTINEL_SHAREPOINT_GRAPH:https://graph.microsoft.com/v1.0}
      drive-id: ${SENTINEL_SHAREPOINT_DRIVE_ID:}
      folder-path: ${SENTINEL_SHAREPOINT_FOLDER:}
      bearer-token: ${SENTINEL_SHAREPOINT_TOKEN:}
      max-files: ${SENTINEL_SHAREPOINT_MAX_FILES:50}
      department: ${SENTINEL_SHAREPOINT_DEPT:ENTERPRISE}
    confluence:
      enabled: ${SENTINEL_CONFLUENCE_ENABLED:false}
      base-url: ${SENTINEL_CONFLUENCE_URL:}
      email: ${SENTINEL_CONFLUENCE_EMAIL:}
      api-token: ${SENTINEL_CONFLUENCE_TOKEN:}
      space-key: ${SENTINEL_CONFLUENCE_SPACE:}
      limit: ${SENTINEL_CONFLUENCE_LIMIT:25}
      max-pages: ${SENTINEL_CONFLUENCE_PAGES:3}
      department: ${SENTINEL_CONFLUENCE_DEPT:ENTERPRISE}
    s3:
      enabled: ${SENTINEL_S3_ENABLED:false}
      bucket: ${SENTINEL_S3_BUCKET:}
      prefix: ${SENTINEL_S3_PREFIX:}
      region: ${SENTINEL_S3_REGION:us-east-1}
      endpoint: ${SENTINEL_S3_ENDPOINT:}
      access-key: ${SENTINEL_S3_ACCESS_KEY:}
      secret-key: ${SENTINEL_S3_SECRET_KEY:}
      max-files: ${SENTINEL_S3_MAX_FILES:100}
      department: ${SENTINEL_S3_DEPT:ENTERPRISE}
      # Additional trusted S3-compatible endpoint domains (beyond built-in AWS, R2, DigitalOcean, Backblaze)
      allowed-domains: ${SENTINEL_S3_ALLOWED_DOMAINS:}

  # HiFi-RAG Pipeline (arXiv:2512.22442v1)
  # Hierarchical filtering + two-pass generation
  # NOTE: Disabled by default - LLM reranking adds significant latency
  hifirag:
    enabled: ${HIFIRAG_ENABLED:false}
    initial-retrieval-k: ${HIFIRAG_INITIAL_K:20}
    filtered-top-k: ${HIFIRAG_FILTERED_K:5}
    relevance-threshold: ${HIFIRAG_RELEVANCE_THRESHOLD:0.5}
    max-iterations: ${HIFIRAG_MAX_ITERATIONS:2}
    reranker:
      # Reranker mode: dedicated (embedding-based model scorer), llm, keyword, or auto.
      mode: ${HIFIRAG_RERANKER_MODE:dedicated}
      batch-size: ${HIFIRAG_RERANKER_BATCH:5}
      timeout-seconds: ${HIFIRAG_RERANKER_TIMEOUT:30}
      # LLM is retained as fallback when dedicated scoring is unavailable.
      use-llm: ${HIFIRAG_USE_LLM:true}
      cache-size: ${HIFIRAG_RERANKER_CACHE_SIZE:2000}
      cache-ttl-seconds: ${HIFIRAG_RERANKER_CACHE_TTL:900}

  # QuCo-RAG: Uncertainty Quantification (arXiv:2512.19134)
  # Detects hallucination risk by analyzing entity frequency
  qucorag:
    enabled: ${QUCORAG_ENABLED:true}
    uncertainty-threshold: ${QUCORAG_THRESHOLD:0.7}
    low-frequency-threshold: ${QUCORAG_LOW_FREQ:1000}
    zero-cooccurrence-penalty: ${QUCORAG_ZERO_PENALTY:0.3}
    # Infini-gram API (optional, requires internet)
    infini-gram-enabled: ${QUCORAG_INFINI_GRAM:false}
    infini-gram-timeout-ms: ${QUCORAG_TIMEOUT:5000}
    infini-gram-index: ${QUCORAG_INDEX:v4_olmo-2-0325-32b-instruct_llama}
    # LLM-based entity extraction (higher accuracy, adds ~200-500ms latency)
    llm-extraction-enabled: ${QUCORAG_LLM_EXTRACTION:false}
    llm-extraction-timeout-ms: ${QUCORAG_LLM_TIMEOUT:3000}

  # MegaRAG: Multimodal Knowledge Graph (arXiv:2512.20626)
  # Cross-modal retrieval for images, charts, and text
  megarag:
    enabled: ${MEGARAG_ENABLED:true}
    # Build joint visual embedding payloads (description + OCR + entities + related text context).
    multimodal-embeddings-enabled: ${MEGARAG_MULTIMODAL_EMBEDDINGS_ENABLED:false}
    multimodal-query-prefix: ${MEGARAG_MULTIMODAL_QUERY_PREFIX:vision query:}
    multimodal-context-max-chars: ${MEGARAG_MULTIMODAL_CONTEXT_MAX_CHARS:1500}
    # Visual retrieval weight vs text (0.0-1.0)
    visual-weight: ${MEGARAG_VISUAL_WEIGHT:0.3}
    # Minimum confidence for cross-modal links
    link-threshold: ${MEGARAG_LINK_THRESHOLD:0.7}
    # Enable chart data extraction
    chart-extraction: ${MEGARAG_CHART_EXTRACTION:true}
    # Enable OCR for image text
    ocr-enabled: ${MEGARAG_OCR:true}
    # Extract embedded images from PDFs during ingestion
    extract-images-from-pdf: ${MEGARAG_EXTRACT_IMAGES:true}

  # MiA-RAG: Mindscape-Aware Retrieval (arXiv:2512.17220)
  # Hierarchical summaries for long-document coherence
  miarag:
    enabled: ${MIARAG_ENABLED:true}
    # Minimum chunks to trigger mindscape building
    min-chunks-for-mindscape: ${MIARAG_MIN_CHUNKS:10}
    # Summarization levels (chunk -> paragraph -> section -> document)
    levels: ${MIARAG_LEVELS:4}
    # Context window for global conditioning
    global-context-tokens: ${MIARAG_CONTEXT_TOKENS:500}

  # Bidirectional RAG: Experience Store (arXiv:2512.22199)
  # Self-improving RAG with grounding verification
  birag:
    enabled: ${BIRAG_ENABLED:true}
    # Minimum grounding score for auto-validation
    grounding-threshold: ${BIRAG_GROUNDING_THRESHOLD:0.8}
    # Use LLM for semantic grounding checks (disable to avoid extra LLM latency)
    use-llm-verification: ${BIRAG_LLM_VERIFICATION:true}
    # LLM verification timeout (ms) for grounding checks
    llm-timeout-ms: ${BIRAG_LLM_TIMEOUT_MS:4000}
    # Novelty detection threshold
    novelty-threshold: ${BIRAG_NOVELTY_THRESHOLD:0.7}
    # Require admin approval for pending experiences
    require-approval: ${BIRAG_REQUIRE_APPROVAL:true}
    # Max experiences to retrieve per query
    max-experiences: ${BIRAG_MAX_EXPERIENCES:5}

  # Hybrid RAG: Reciprocal Rank Fusion (arXiv:2512.12694)
  # Combines semantic and keyword retrieval with OCR tolerance
  hybridrag:
    enabled: ${HYBRIDRAG_ENABLED:true}
    # RRF k parameter (higher = more emphasis on top ranks)
    rrf-k: ${HYBRIDRAG_RRF_K:60}
    # Weight for semantic retrieval (keyword weight = 1 - semantic)
    semantic-weight: ${HYBRIDRAG_SEMANTIC_WEIGHT:0.6}
    keyword-weight: ${HYBRIDRAG_KEYWORD_WEIGHT:0.4}
    # Number of query variants for multi-query retrieval
    multi-query-count: ${HYBRIDRAG_MULTI_QUERY:3}
    # OCR error tolerance (common character substitutions)
    ocr-tolerance: ${HYBRIDRAG_OCR_TOLERANCE:true}
    # LLM-based query expansion (higher quality, adds latency)
    llm-expansion: ${HYBRIDRAG_LLM_EXPANSION:false}
    # Query expansion cache (reduces repeated LLM/expansion work)
    query-expansion-cache-size: ${HYBRIDRAG_QE_CACHE_SIZE:1500}
    query-expansion-cache-ttl-seconds: ${HYBRIDRAG_QE_CACHE_TTL:900}

  # Graph-O1: MCTS Graph Reasoning (arXiv:2512.17912)
  # Monte Carlo Tree Search for knowledge graph traversal
  # NOTE: Disabled by default - MCTS iterations are slow
  grapho1:
    enabled: ${GRAPHO1_ENABLED:false}
    # Maximum MCTS iterations
    max-iterations: ${GRAPHO1_MAX_ITER:50}
    # UCB1 exploration constant (sqrt(2) is common)
    exploration-constant: ${GRAPHO1_EXPLORE_C:1.414}
    # Maximum reasoning depth in graph
    max-depth: ${GRAPHO1_MAX_DEPTH:5}
    # Simulations per node evaluation
    simulation-count: ${GRAPHO1_SIM_COUNT:3}
    # Minimum confidence for early termination
    min-confidence: ${GRAPHO1_MIN_CONF:0.6}

  # AdaptiveRAG: Intelligent Query Routing (arXiv:2504.20734)
  # Routes queries to optimal retrieval strategy based on complexity
  adaptiverag:
    enabled: ${ADAPTIVERAG_ENABLED:true}
    # Use LLM for semantic routing (higher accuracy, +3-5s latency)
    # Default false: uses fast heuristics only to avoid per-query LLM overhead
    semantic-router-enabled: ${ADAPTIVERAG_SEMANTIC_ROUTER:false}
    # LLM semantic router timeout (ms)
    semantic-router-timeout-ms: ${ADAPTIVERAG_ROUTER_TIMEOUT_MS:3000}
    chunk-top-k: ${ADAPTIVERAG_CHUNK_K:5}
    document-top-k: ${ADAPTIVERAG_DOCUMENT_K:3}

  # CRAG: Corrective RAG (Document Grading)
  # Validates retrieved documents before generation to reduce hallucinations
  # NOTE: LLM grading disabled by default for speed - use keyword-based grading
  crag:
    enabled: ${CRAG_ENABLED:true}
    # Minimum ratio of CORRECT documents to proceed with generation
    min-correct-threshold: ${CRAG_MIN_CORRECT:0.5}
    # Use LLM for document grading (higher accuracy, higher latency)
    use-llm-grading: ${CRAG_LLM_GRADING:false}
    # Query rewrite timeout (ms) when retrieval fails
    rewrite-timeout-ms: ${CRAG_REWRITE_TIMEOUT_MS:2000}
    # Confidence threshold for accepting retrieval results
    confidence-threshold: ${CRAG_CONFIDENCE:0.6}

  # HyDE: Hypothetical Document Embeddings
  # Improves retrieval for vague/conceptual queries
  # NOTE: Disabled - requires LLM call for hypothetical doc generation
  hyde:
    enabled: ${HYDE_ENABLED:false}
    top-k: ${HYDE_TOP_K:10}
    similarity-threshold: ${HYDE_THRESHOLD:0.25}
    # Maximum length of hypothetical document
    hypothetical-length: ${HYDE_LENGTH:150}

  # Self-RAG: Self-Reflective Generation
  # Model critiques its own claims for maximum factual accuracy
  # NOTE: Disabled by default - adds 2-3 LLM calls per query
  selfrag:
    enabled: ${SELFRAG_ENABLED:false}
    # Max uncertain claims before triggering re-retrieval
    max-uncertain-claims: ${SELFRAG_MAX_UNCERTAIN:2}
    # Re-retrieve when too many uncertain claims detected
    re-retrieve-on-uncertain: ${SELFRAG_RE_RETRIEVE:true}

  # Agentic RAG Orchestrator
  # Full pipeline coordination for complex queries (Government edition)
  agentic:
    # DISABLED BY DEFAULT - enable for government edition
    enabled: ${AGENTIC_ENABLED:false}
    max-iterations: ${AGENTIC_MAX_ITER:3}
    use-hyde: ${AGENTIC_USE_HYDE:true}
    use-selfrag: ${AGENTIC_USE_SELFRAG:true}
    confidence-threshold: ${AGENTIC_CONFIDENCE:0.6}
    # Phase 4.2: cap evidence breadth to preserve synthesis quality.
    documents-per-query-ceiling: ${AGENTIC_DOCUMENTS_PER_QUERY_CEILING:40}
    # Phase 4.2: quick persona for short/direct questions; careful investigator otherwise.
    quick-lookup-max-terms: ${AGENTIC_QUICK_LOOKUP_MAX_TERMS:9}

  # LightOnOCR Service Integration
  # AI-powered OCR for scanned PDFs and document images
  ocr:
    enabled: ${OCR_ENABLED:false}
    service-url: ${OCR_SERVICE_URL:http://localhost:8090}
    timeout-seconds: ${OCR_TIMEOUT_SECONDS:60}
    max-tokens-per-page: ${OCR_MAX_TOKENS:2048}
    max-pages: ${OCR_MAX_PAGES:50}
    # Automatically use OCR for PDFs with little extractable text
    fallback-for-scanned-pdf: ${OCR_FALLBACK_SCANNED:true}

  # PII Redaction Engine
  # Industry-standard compliance: NIST 800-122, GDPR, HIPAA Safe Harbor, PCI-DSS
  pii:
    enabled: ${PII_ENABLED:true}
    mode: ${PII_MODE:MASK}  # MASK, TOKENIZE, or REMOVE
    audit-redactions: ${PII_AUDIT:true}
    patterns:
      ssn: ${PII_SSN:true}
      email: ${PII_EMAIL:true}
      phone: ${PII_PHONE:true}
      credit-card: ${PII_CREDIT_CARD:true}
      dob: ${PII_DOB:true}
      date: ${PII_DATE:true}
      age: ${PII_AGE:true}
      ip-address: ${PII_IP:true}
      passport: ${PII_PASSPORT:true}
      drivers-license: ${PII_DL:true}
      account-number: ${PII_ACCOUNT:true}
      health-plan-id: ${PII_HEALTH_PLAN:true}
      certificate-number: ${PII_CERTIFICATE:true}
      vehicle-id: ${PII_VEHICLE:true}
      device-id: ${PII_DEVICE:true}
      url: ${PII_URL:true}
      biometric: ${PII_BIOMETRIC:true}
      names: ${PII_NAMES:false}
      address: ${PII_ADDRESS:true}
      medical-id: ${PII_MEDICAL:true}

  # Glass Box Reasoning Engine
  # Real-time pipeline transparency
  reasoning:
    enabled: ${REASONING_ENABLED:true}
    detailed-traces: ${REASONING_DETAILED:false}
    trace-retention-hours: ${REASONING_RETENTION:24}

  # UI Theming Configuration
  # Sector-aware theming: GOVERNMENT, MEDICAL, ENTERPRISE
  ui:
    # Default sector theme (matches the 3 sectors)
    default-sector: ${SENTINEL_DEFAULT_SECTOR:ENTERPRISE}
    # Custom branding (optional)
    brand-name: ${SENTINEL_BRAND_NAME:SENTINEL}
    # Show classification banners (high-security sectors: GOVERNMENT, MEDICAL)
    show-classification: ${SENTINEL_SHOW_CLASSIFICATION:true}
    # Allow users to switch sectors
    allow-sector-switching: ${SENTINEL_ALLOW_SECTOR_SWITCH:true}

  # HIPAA strict mode (Medical edition)
  hipaa:
    # Enable strict mode via env, or default-on for Medical edition
    strict: ${HIPAA_STRICT:false}
    enable-for-medical-edition: ${HIPAA_ENFORCE_MEDICAL:true}
    # Disable persistence/exports and sensitive subsystems in strict mode
    redact-responses: ${HIPAA_REDACT_RESPONSES:true}
    disable-feedback: ${HIPAA_DISABLE_FEEDBACK:true}
    disable-session-memory: ${HIPAA_DISABLE_SESSION_MEMORY:true}
    disable-session-export: ${HIPAA_DISABLE_SESSION_EXPORT:true}
    disable-visual: ${HIPAA_DISABLE_VISUAL:true}
    disable-experience-learning: ${HIPAA_DISABLE_EXPERIENCE:true}
    suppress-sensitive-logs: ${HIPAA_SUPPRESS_LOGS:true}
    # Enforce TLS on non-govcloud profiles when strict mode is required
    enforce-tls: ${HIPAA_ENFORCE_TLS:true}
    # Automatic logoff via server session timeout (minutes)
    session-timeout-minutes: ${HIPAA_SESSION_TIMEOUT_MINUTES:15}
    oidc:
      # Override OIDC defaults for medical deployments
      auto-provision: ${HIPAA_OIDC_AUTO_PROVISION:false}
      require-approval: ${HIPAA_OIDC_REQUIRE_APPROVAL:true}
      require-mfa: ${HIPAA_OIDC_REQUIRE_MFA:true}

  kms:
    enabled: ${KMS_ENABLED:false}
    region: ${KMS_REGION:}
    endpoint: ${KMS_ENDPOINT:}

  integrity:
    # HMAC signing key for session exports/traces (required for medical deployments)
    secret-key: ${SENTINEL_INTEGRITY_SECRET:}
    # Rotation-ready keyring: keyId:base64 pairs (comma-separated)
    active-key-id: ${INTEGRITY_ACTIVE_KEY_ID:}
    keys: ${INTEGRITY_KEYS:}
    # KMS-encrypted keyring entries (keyId:ciphertextBase64)
    keys-kms: ${INTEGRITY_KEYS_KMS:}

# ============================================
# Swagger/OpenAPI Configuration
# ============================================
springdoc:
  api-docs:
    path: /v3/api-docs
  swagger-ui:
    path: /swagger-ui.html
    # SECURITY: Disabled by default in production. Enable only for dev.
    enabled: ${SWAGGER_ENABLED:false}
    operationsSorter: method
    tagsSorter: alpha
    filter: true
    showExtensions: true
    showCommonExtensions: true
  show-actuator: false

# ============================================
# Profile-specific configurations
# ============================================

---
# DEVELOPMENT PROFILE
spring:
  config:
    activate:
      on-profile: dev

server:
  servlet:
    session:
      cookie:
        secure: false

app:
  auth-mode: DEV
  dev:
    allow-remote: ${DEV_ALLOW_REMOTE:false}

# Enable Swagger UI for development
springdoc:
  swagger-ui:
    enabled: true

---
# ENTERPRISE PROFILE (Azure AD / Okta)
spring:
  config:
    activate:
      on-profile: enterprise

app:
  auth-mode: OIDC
  oidc:
    issuer: ${OIDC_ISSUER}
    client-id: ${OIDC_CLIENT_ID}
    jwks-uri: ${OIDC_JWKS_URI:}
    local-jwks-path: ${OIDC_LOCAL_JWKS:}
    jwks-cache-ttl: ${OIDC_JWKS_CACHE_TTL:3600}
    allowed-algorithms: ${OIDC_ALGORITHMS:RS256,RS384,RS512,ES256}
    clock-skew-seconds: ${OIDC_CLOCK_SKEW:30}  # SECURITY: Reduced from 60s for tighter validation
    validate-issuer: ${OIDC_VALIDATE_ISSUER:true}
    validate-audience: ${OIDC_VALIDATE_AUDIENCE:true}
    auto-provision: ${OIDC_AUTO_PROVISION:true}
    require-approval: ${OIDC_REQUIRE_APPROVAL:false}
    require-mfa: ${OIDC_REQUIRE_MFA:false}
    mfa-claim-values: ${OIDC_MFA_CLAIMS:mfa,otp,pwd+otp,hwk}
    mfa-acr-values: ${OIDC_MFA_ACR:}
    default-role: ${OIDC_DEFAULT_ROLE:VIEWER}
    default-clearance: ${OIDC_DEFAULT_CLEARANCE:UNCLASSIFIED}
    # Browser OIDC flow (Authorization Code + PKCE)
    authorization-uri: ${OIDC_AUTHORIZATION_URI:}
    token-uri: ${OIDC_TOKEN_URI:}
    redirect-uri: ${OIDC_REDIRECT_URI:}
    scopes: ${OIDC_SCOPES:openid profile email}

---
# GOVERNMENT/GOVCLOUD PROFILE (CAC/PIV)
spring:
  config:
    activate:
      on-profile: govcloud

app:
  auth-mode: CAC
  cac:
    # SECURITY: Disable auto-provisioning by default in govcloud
    # New CAC users must be pre-registered by an administrator
    auto-provision: ${CAC_AUTO_PROVISION:false}
    # Require admin approval for any auto-provisioned CAC user
    require-approval: ${CAC_REQUIRE_APPROVAL:true}
    # Least-privilege defaults if auto-provision is enabled
    default-role: ${CAC_DEFAULT_ROLE:VIEWER}
    default-clearance: ${CAC_DEFAULT_CLEARANCE:UNCLASSIFIED}
    chain-validation:
      enabled: ${CAC_CHAIN_VALIDATION_ENABLED:true}
      # Fail closed in SCIF deployments if chain validation is enabled but no trust store is configured.
      require-truststore: ${CAC_CHAIN_VALIDATION_REQUIRE_TRUSTSTORE:true}
    truststore:
      path: ${CAC_TRUSTSTORE_PATH:}
      password: ${CAC_TRUSTSTORE_PASSWORD:}
    # Revocation checking is recommended for government deployments. Provide a local CRL file.
    crl-check-enabled: ${CAC_CRL_CHECK_ENABLED:true}
    crl-path: ${CAC_CRL_PATH:}

sentinel:
  demo:
    enabled: false
  connectors:
    enabled: false
  airgap:
    model-validation:
      # GovCloud/SCIF deployments must use locally pre-loaded models (no internet).
      enabled: ${AIRGAP_MODEL_VALIDATION_ENABLED:true}
      fail-on-missing: ${AIRGAP_MODEL_VALIDATION_FAIL:true}
      timeout-ms: ${AIRGAP_MODEL_VALIDATION_TIMEOUT_MS:2000}

# Disable Swagger UI in government deployments
springdoc:
  swagger-ui:
    enabled: false

# For air-gapped deployments, override MongoDB URI:
# MONGODB_URI=mongodb://localhost:27017/mercenary

---
# COMMERCIAL/STANDARD PROFILE (Username/Password)
spring:
  config:
    activate:
      on-profile: standard

app:
  auth-mode: STANDARD
  standard:
    allow-basic: false

sentinel:
  bootstrap:
    enabled: ${SENTINEL_BOOTSTRAP_ENABLED:false}
    reset-admin: ${SENTINEL_BOOTSTRAP_RESET_ADMIN:false}
    admin-password: ${SENTINEL_BOOTSTRAP_ADMIN_PASSWORD:${SENTINEL_ADMIN_PASSWORD:}}
