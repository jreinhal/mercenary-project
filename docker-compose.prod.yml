# SENTINEL Intelligence Platform - Production Docker Compose
# Hardened configuration for enterprise/government deployments

version: '3.8'

services:
  # SENTINEL Application - Production settings
  sentinel:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        EDITION: ${EDITION:-government}
    container_name: sentinel-app
    restart: always
    ports:
      - "8080:8080"
    environment:
      - APP_PROFILE=${APP_PROFILE:-standard}
      - AUTH_MODE=${AUTH_MODE:-STANDARD}
      - SPRING_DATA_MONGODB_URI=mongodb://mongo:27017/sentinel
      - SPRING_AI_OLLAMA_BASE_URL=http://ollama:11434
      - SPARSE_EMBEDDING_URL=http://sparse-embedding:8091
      - JAVA_OPTS=-Xms1g -Xmx4g -XX:+UseG1GC -XX:MaxGCPauseMillis=200
    depends_on:
      mongo:
        condition: service_healthy
      ollama:
        condition: service_started
    networks:
      - sentinel-network
    # Strict resource limits
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 6G
        reservations:
          cpus: '1.0'
          memory: 1G
    # Security options
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:size=100M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s

  # MongoDB - Production settings
  mongo:
    image: mongo:7.0
    container_name: sentinel-mongo
    restart: always
    ports:
      - "127.0.0.1:27017:27017"  # Bind to localhost only
    volumes:
      - mongo_data:/data/db
      - mongo_config:/data/configdb
    environment:
      - MONGO_INITDB_DATABASE=sentinel
    networks:
      - sentinel-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 512M
    security_opt:
      - no-new-privileges:true
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Ollama - Production settings
  ollama:
    image: ollama/ollama:0.5.4
    container_name: sentinel-ollama
    restart: always
    ports:
      - "127.0.0.1:11434:11434"  # Bind to localhost only
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - sentinel-network
    deploy:
      resources:
        limits:
          cpus: '8.0'
          memory: 16G
        reservations:
          cpus: '2.0'
          memory: 4G

  # FlagEmbedding Sparse Embedding Sidecar (Optional)
  # Provides BGE-M3 learned sparse (lexical) weights for hybrid retrieval.
  # Start with: docker compose --profile sparse -f docker-compose.prod.yml up
  # Enable via SPARSE_EMBEDDING_ENABLED=true on the sentinel service.
  sparse-embedding:
    profiles:
      - sparse
    build:
      context: ./tools/sparse-embedding-sidecar
      dockerfile: Dockerfile
    container_name: sentinel-sparse-embedding
    restart: always
    ports:
      - "127.0.0.1:8091:8091"
    environment:
      - DEVICE=cpu
      - MODEL_NAME=BAAI/bge-m3
    networks:
      - sentinel-network
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 6G
        reservations:
          cpus: '1.0'
          memory: 2G
    security_opt:
      - no-new-privileges:true
    # Model is baked into the image at build time (see Dockerfile).
    # read_only is safe because no runtime downloads are needed.
    read_only: true
    tmpfs:
      - /tmp:size=500M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8091/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 180s

networks:
  sentinel-network:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"

volumes:
  mongo_data:
    driver: local
  mongo_config:
    driver: local
  ollama_data:
    driver: local
